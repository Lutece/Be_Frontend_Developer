# 메모리 계층

메모리 장치의 계층 구조를 도식화한 그림

레지스터  
캐시 메모리
메모리
저장 장치

아래부터 위

- 사이즈 큼 -> 작음
- 가격 쌈 -> 비쌈
- 접근속도 느림 -> 빠름

## 캐시 메모리

컴퓨터의 동작흐름은 아래와 같다

1. 명령어를 바탕으로 메모리에서 레지스터로 데이터를 읽는다.
2. 레지스터에 있는 데이터를 바탕으로 계산한다.
3. 계산 결과를 메모리에 쓴다.

캐시 메모리는 레지스터 안에서 계산하는 것과 메모리에 접근하는 것, 양쪽의 처리 시간의 차이를 메우는 역할을 한다.

캐시 메모리로부터 레지스터에 접근할 때의 레이턴시는 메모리에 접근할 때와 비교해보면 수배에서 수십배 빠른 점을 이용해 속도를 고속화한다. 캐시 메모리는 일반적으로 CPU에 내장되어 있지만 CPU의 바깥에 있는 캐시 메모리도 있다.

메모리에서 레지스터로 데이터를 읽어올 때는, 일단 캐시 메모리에 읽어온 뒤 같은 내용을 다시 레지스터로 읽어들인다. 이때 읽어오는 크기는 CPU에서 정한 '캐시 라인 사이즈'만큼이다.

메모리로부터 읽어 들인 데이터가 변경되었음을 플래그로 표시하는 데 이 표시된 라인을 '더티'라고 한다.
이 더티 플래그가 붙어 있는 데이터는 나중에 백그라운드 처리로 메모리에 다시 기록된다. 다시 기록되면 더티 플래그는 사라진다.

### 캐시 메모리가 가득 찬 경우

캐시 메모리가 가득 찬 경우, 캐시 메모리에 존재하지 않는 데이터를 추가로 읽으면 기존의 캐시 메모리 중 1개를 파기한다. 파기되어 비워진 라인에 새 데이터를 넣는다.

캐시 메모리가 가득 차고 모든 캐시 라인이 더티라면 메모리 접근을 할 때마다 캐시 라인 안의 데이터가 자주 바뀌는 스래싱이 발생하여 성능이 크게 감속할 수 있다.

### 메모리 참조의 국소성

(국소성: 충분히 멀리 떨어진 두 물체는 곧바로 상용하지 않는다는 원리)

프로세스의 데이터가 전부 캐시에 있는 동안에는 데이터에 접근하는 속도는 메모리에 접근하는 속도가 아니라 이보다 빠른 캐시에 접근하는 속도이다. 프로그램은 대부분 메모리 참조의 국소성이라고 하는 다음과 같은 특성이 있다.

- 시간 국소성: 특정 시점에서 접근하는 데이터는 가까운 미래에 다시 접근할 가능성이 크다. 전형적인 예로는 루프 처리중인 코드 영역을 들 수 있다.
- 공간 국소성: 특정 시점에 어떤 데이터에 접근하면 그 데이터와 가까운 주소에 있는 데이터를 접근할 확률이 높다. 전형적인 예로는 배열의 전체 검색 등을 들 수 있다.

이러한 이유로 프로세스는 짧은 시간을 놓고 생각해보면, 자신이 획득한 메모리의 총량보다 훨씬 좁은 범위의 메모리에 접근하는 성향이 있다. 이 좁은 범위를 캐시 메모리의 사이즈가 커버할 수 있으면 성능이 좋은 것이다.

### 정리

프로그램의 워크로드를 캐시 메모리 사이즈에 들어가게 하는 것으로 성능을 크게 향상시킬 수 있다.
속도를 중요시하는 프로그램이라면 캐시 메모리의 효과를 최대한으로 끌어내기 위해 데이터의 배열이나 알고리즘 혹은 설정을 연구해서 단위 시간 당 메모리 접근 범위를 작게 하는 것이 중요하다.

한편, 시스템 설정을 변경했을 때 프로그램의 성능이 크게 나빠진 경우에는 프로그램의 데이터가 캐시 메모리에 전부 들어가지 않았을 가능성이 있다.

## Translation Lookaside Buffer

프로세스는 다음과 같은 순서에 따라 가상 주소의 데이터에 접근한다.

1. 물리 메모리상에 존재하는 페이지 테이블을 참고하여 가상 주소를 물리 주소로 변환한다.
2. 1에서 구한 물리 메모리에 접근한다.

캐시 메모리를 사용하여 고속화하는 것은 2번뿐이다. 왜냐하면 1은 물리 메모리상에 있는 페이지 테이블에 접근해야 하므로 캐시가 동작할 수 없다.

이 문제를 해결하기 위해 CPU에는 가상 주소에서 물리 주소로의 변환표를 보관하는 한편, 캐시 메모리와 똑같이 고속으로 접근 가능한 TLB 라는 영역이 있다. 이것을 가지고 1을 고속화 한다.

### 페이지 캐시

CPU로부터 메모리에 접근하는 속도에 비해 저장 장치에 접근하는 속도는 엄청나게 느리다.
이 속도 차이를 줄이기 위해 커널에는 '페이지 캐시'기능이 있다.

페이지 캐시는 캐시 메모리와 매우 비슷하다
캐시 메모리가 메모리의 데이터를 캐싱하느 ㄴ것과 비슷하게 페이지 캐시는 저장 장치 내의 파일 데이터를 메모리에 캐싱한 것이다.

캐시 메모리는 캐시 라인 단위로 데이터를 다루지만 페이지 캐시는 페이지 단위로 데이터를 다룬다.
페이지 캐시의 동작 흐름을 구체적으로 살펴본다.

프로세스가 파일의 데이터를 읽어 들이면 커널은 프로세스의 메모리에 파일의 데이터를 직접 복사하는 것이 아니라 커널의 메모리 내에 있는 페이지 캐시라는 영역에 복사한 뒤 이 데이터를 프로세스 메모리에 복사한다.

커널은 자신의 메모리 안에 페이지 캐시에 캐싱한 파일과 그 범위 등의 정보를 보관하는 관리 영역을 가지고 있다.

그리고 페이지 캐시에 존재하는 데이터를 다시 읽으면 커널은 페이지 캐시의 데이터를 돌려준다.

이 방법은 저장 장치에 접근하는 경우에 비해 훨씬 더 빠르게 처리된다.
또한 페이지 캐시는 전체 프로세스 공유의 자원이므로 읽어 들인 프로세스는 최초에 파일 데이터에 접근한 프로세스와 다른 프로세스여도 문제가 없다.

### 페이지 캐시 쓰기

프로세스가 데이터를 파일에 쓰면 커널은 페이지 캐시에 데이터를 쓴다.
이때 관리 영역 내에 해당하는 데이터에 대응되는 엔트리에 '데이터의 내용은 저장 장치의 내용보다 새로운 것'이라는 플래그를 붙여둔다. 이 플래그가 붙은 페이지를 더티 페이지라고 부른다.

이것도 읽기와 마찬가지로 저장 장치에 접근하는 것에 비해 훨씬 더 빠르게 처리된다.
더티 페이지의 내용은 나중에 커널의 백그라운드로 처리하며 스토리지 내의 파일에 반영한다.
이때 더티 페이지의 플래그를 지운다.

각 프로세스가 접근하는 파일의 데이터가 전부 페이지 캐시에 있으면 시스템 파일의 접근 속도는 저장 장치의 접근 속도가 아닌 메모리 접근 속도에 근접하므로 시스템 전체가 빠르게 동작한다.

또한 페이지 캐시 사이즈는 시스템의 메모리가 비어 있는 한, 시스템 내의 각 프로세스가 페이지 캐시에 없는 파일을 읽을 때마다 점점 증가한다.

시스템 메모리가 부족해지면 커널은 페이지 캐시를 해제하여 빈 영역을 만든다. 이 경우 더티가 아닌 페이지를 파기한다. 그래도 시스템 메모리가 부족하면 더티 페이지를 라이트 백 한 뒤에 파기한다.
더티 페이지는 저장 장치 접근이 발생하므로 시스템의 성능이 느려지는 문제점이 있다. 파일에 쓰기가 많아서 더티 페이지가 많아지는 시스템은 부하가 많아질 수 밖에 없다. 메모리 부족이 더티 페이지의 라이트 백을 자주 발생시켜 시스템이 느려지는 일은 굉장히 자주 있다.

## 버퍼 캐시

페이지 캐시와 비슷한 구조로 버퍼 캐시라는 것이 있다.
이것은 파일시스템을 사용하지 않고 나중에 설명할 디바이스 파일을 이용하여 저장 장치에 직접 접근하는 등의 목적으로 사용한다.

페이지 캐시와 버퍼 캐시를 합쳐서 저장 장치 안의 데이터를 메모리에 넣어두는 방식이라 한다.

## 정리

파일의 데이터가 페이지 캐시에 있다면 없는 경우와 비교해서 파일 접근이 매우 빨라진다.
그렇게 하기 위해서는 시스템이 접근하는 파일의 사이즈나 물리 메모리의 양을 비교하여 맞추는 것이 중요하다.

설정 변경이나 시간이 지나면서 시스템의 성능이 갑자기 느려졌다면 파일의 데이터가 페이지 캐시에 제대로 들어가지 못했을 수 있다. 여러가지 sysctl 파라미터를 잘 튜닝한다면 페이지 캐시의 라이트 백이 자주 발생하여서 생기는 I/O 부하를 막을 수 있다. 또한 sar - B나 sar -d -p등을 이용하여 페이지 캐시에 관한 통계 정보를 얻을 수 있다.
